---
title: "Network analysis based on dataset with raw reads"
author: "Xiu Jia"
date: "2024-11-27"
output: 
html_document:
number_sections: true
editor_options: 
 chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


I used the script from the "Network Analysis Workshop" of National Centre for Soil Ecology Day on October 30, 2024, which is hosted by: Natalie Oram (UvA: n.j.oram@uva.nl) and Doina Bucur (UTwente: d.bucur@utwente.nl). It is suggested by Tianci on 25 Nov 2024 and implemented on 2 December 2024.

## This script outlines 7 steps to creating co-occurrence networks
* The networks are built with with Spiec.Easi: https://github.com/zdk123/SpiecEasi, visualized with igraph: https://r.igraph.org/ and topology determined with various packages (igraph, braingraph).
* We will use the feature table generated by Kraken2, raw number of reads in the table. These data have been aggregated to the Family level to reduce the number of nodes (taxa). In total, we have data from 120 full and 120 seawater culture media, and 453 different bacterial families.

## Further reading:
- Kurtz et al., 2015. https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004226
- Chen et al., 2024. https://arxiv.org/pdf/2407.03897
- Chen and Bucur, 2024. https://link.springer.com/chapter/10.1007/978-3-031-57515-0_13
- Caruso et al., 2022. https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13985
- Gueseva et al., 2022. https://www.sciencedirect.com/science/article/pii/S003807172200061X
- Shan et al., 2023. https://www.nature.com/articles/s41559-023-02021-z


```{r, include = FALSE}
# Prepare the library and work directory
# clean the work enviornment
rm(list=ls())

# Install the packages if necessary. Sometimes SpiecEasi can be a bit moody, but in the newest version of R (4.4.1) it installs fine :-) 

# library(devtools)
# install_github("zdk123/SpiecEasi")
# library(SpiecEasi)

# packages <- c("phyloseq", "microbiome", "ggnet",
#            "DescTools", "qgraph", "brainGraph", "ggthemes")
# 
# # Identify packages that are not yet installed
# packages_to_install <- packages[!(packages %in% installed.packages()[,"Package"])]

# Install missing packages
# if (length(packages_to_install) > 0) {
#  install.packages(packages_to_install)
# } else {
#  message("All packages are already installed!")
# }

# if (!require("BiocManager", quietly = TRUE))
#  install.packages("BiocManager")
# 
# BiocManager::install("phyloseq")
# 
# library(BiocManager)
# BiocManager::install("microbiome")
```

Load libraries
```{r, message = FALSE, warning = FALSE}

# Libraries
library(tidyverse) 
library(phyloseq)
library(microbiome)

library(devtools)
library(SpiecEasi) # building network
library(igraph) # visualizing network + topology
library(intergraph) # for final network figures
library(network) # for final network figures
library(graph4lg) # for re-building null model ensemble in R
library(ggnet)

# packages for network topology
library(DescTools) # for calculating area under the curve
library(qgraph) # for calculating small worldness
library(brainGraph) # calculating network robustness

library(ggthemes) # for nice plot layouts
library(cowplot) # to easily combine multiple plots

# change work directory
base_path <- "network_Spiec_Easi_rawreads/"

```

# Step 1: Load data (raw reads) and filter data 
Not done for this dataset as it is already aggregated to the family level, leaving 453 taxa (total read count at family level) (which is fine for the network to handle). This is one option of reducing the amount of nodes in the dataset. \n

How you filter data is an important question to consider. One option is to remove low-abundance taxa or taxa that only occur in a small proportion of your experimental units. E.g. if taxa are only present in 5% of your 4 bacterial communities from seawater condition, it is likely that they don't play an important role in your co-occurrence network (as their chance to 'co-occur' is quite small). How many nodes a network can handle will depend on the dataset (the variation in data). There's no hard and fast number for this, but around 200-800 nodes generally works fine. 
```{r}

## Load data
## The data format we need is a phyloseq object. Here, we combine the OTU table, (simplified) taxonomy table, and the sample metadata (all .csv files) into a phyloseq object. If you have the phloseq object, just start from there. 

# read phyloseq object
ps_rawreads <- readRDS("phyloseq_object_family_microcosm_raw_reads.rds")

# check
ps_rawreads
summary(sample_data(ps_rawreads))
otu_table(t(ps_rawreads))[1:3, 1:3]


# Remove taxa not seen more than 5 times in at least 2% of the samples. This protects against an taxa with small mean & trivially large C.V.

# Filter taxa: more than 5 reads in at least 2% of samples
# min_samples <- ceiling(0.02 * nsamples(ps_rawreads))
# min_samples

# Remove taxa not seen more than 4 times of the samples. This protects against an taxa with small mean & trivially large C.V.
ps_rawreads_filtered <- filter_taxa(ps_rawreads, function(x) sum(x != 0) >= 4, prune = TRUE) # or replace the number by min_samples
ps_rawreads_filtered

```

# Step 2: Network construction for the full dataset 
Below is the code to construct the network. This step is heavy on computational memory and very slow. So I have constructed networks in advance and loaded it later on. See https://github.com/zdk123/SpiecEasi for more details. This input for SPIEC-EASI is a counts table.  The normalization and tranformation is done by the function. \n More information on [SPIEC-EASI](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004226).  


- Ingredients
- method: can be 'mb' (Neighborhood selection) or 'glasso' (inverse covariance selection)
- nlambda: tells the model how many different lambda values to try (how many ways to wire each node pair in the network). This essentially determines how complex your network is. A value between 20-120 is fine. Higher nlambda = more computational time and very high nlambda (> 150 or so) risks over fitting.
- lambda.min.ratio: determines/constrains the range of nlambda values (i.e. 1e-2 means that the smallest lambda value is 1% of the largest)
- pulsar.params: rep.num = number of times the network is re-sampled (bootstrapped), thresh: sets the stability threshold for edges in the network. 0.05 means that an edge must occur in 5% of the bootstrapped samples to be considered in the final model.
- sel.criterion: model sparseness is inferred using the Stability Approach to Regularization Selection (StARS), which involves random sub-sampling of the data set to find a network with low variability in the selected set of edges. character string specifying criterion/method for model selection. Accepts 'stars' [default], 'bstars' (Bounded StARS)

- The goal is to have a stable network >> target stability threshold (getStability) should be very close to 0.05. To improve the stability score, you can adjust:
- nlambda
- lambda.min.ratio
- sel.criterion

```{r}

# I used the full dataset to build the network

# change the base path where to save the outputs accordingly.

base_path <- "network_Spiec_Easi_rawreads_full/"

# ## Parallel multicore ##
# pargs <- list(rep.num=20, seed=210, ncores=4, thresh=0.05) # this is much faster by using more cores
# 
# ## Construct the network
# network_full_filtered <- spiec.easi(ps_rawreads_filtered, method='mb',nlambda=100, lambda.min.ratio=1e-2,
#                                      pulsar.params=pargs, sel.criterion='bstars')
# 
# getStability(network_full_filtered) # Should be close to 0.05
# 
# ## Save network
# saveRDS(network_full_filtered, paste0(base_path, "network_full_filtered.rds"))

## Load network 
network_full_filtered <- readRDS(paste0(base_path, "network_full_filtered.rds"))
getStability(network_full_filtered) # 0.04996942: this is acceptable!

# Convert adjacency network to igraph format
ig_network_full_filtered <- adj2igraph(getRefit(network_full_filtered), diag=TRUE,
                                       vertex.attr=list(name=taxa_names(ps_rawreads_filtered)))
ig_network_full_filtered 

## Extract edge list and attributes 
edgelist_network_full_filtered <- as_edgelist(ig_network_full_filtered, names = FALSE)
edgelist_network_full_filtered <- as.data.frame(edgelist_network_full_filtered)
edgelist_network_full_filtered[1:5,]
# write.csv(edgelist_network_full_filtered, paste0(base_path, "full_network_edgelist.csv"))

## Extract adjacency matrix
adj_network_full_filtered <- as_adjacency_matrix(ig_network_full_filtered, sparse=FALSE)
adj_network_full_filtered <- as.data.frame(adj_network_full_filtered)
adj_network_full_filtered[1:3, 1:2]
# write.csv(adj_network_full_filtered, paste0(base_path, "full_network_adj_matrix.csv"))

```

#### extract taxa belonging to each node
You can replace `cluster_louvain()` with other algorithms like:
* `cluster_fast_greedy()`
* `cluster_edge_betweenness()`
* `cluster_walktrap()`
```{r}
# Use the adjacency network in igraph format
ig_network_full_filtered[1:5, 1:5] 

# using a module detection algorithm
modules <- cluster_louvain(ig_network_full_filtered)

# extract nodes in each module and group them
membership_vector <- membership(modules)
modules <- split(V(ig_network_full_filtered)$name, membership_vector) #  get the vertex list by V()
modules 

# Convert to a data frame
df <- data.frame(
  Group = rep(names(modules), sapply(modules, length)),
  Item = unlist(modules)
)

print(df)

# write.csv(df, paste0(base_path, "module_list.csv"))

df <- data.frame(
  Node = unlist(modules ),
  Module = rep(names(modules), lengths(modules))
)

# Save to a file
write.csv(df, paste0(base_path, "modules.csv"))

```

# Step 3: Visualize the network 
```{r}

#### full_dataset -------------
# Set weights of nodes
## Extract the OTU table from the phyloseq object used in the network 
otu_table <- otu_table(ps_rawreads_filtered)
otu_df <- as.data.frame(otu_table) 
dim(otu_table)
otu_table[1:3, 1:3]

# Xiu, why add 3, make it more positive?
vsize <- rowMeans(clr(otu_table)) +3  # use OTU object here
vsize_df <- as.data.frame(vsize)
head(vsize_df)

# Build a network with igraph
# adj_matrix <- as_adjacency_matrix(ig_network_full_filtered, sparse=FALSE)
# g <- graph_from_adjacency_matrix(adj_matrix, mode="undirected", diag=FALSE)
# plot(g)

am_coord <- igraph::layout_with_fr(ig_network_full_filtered)
head(am_coord)

# Simple Plots
plot_full <- plot(ig_network_full_filtered, layout=am_coord, vertex.size = vsize, vertex.label=NA)

plot_network(ig_network_full_filtered, ps_rawreads_filtered, type='taxa', color="Class", alpha = 0.5) + theme(legend.position="none")

```


# Step 4: Create the Null Model Ensemble

We need to do this in python separately and open it back to R.

```{r, eval=FALSE}
# I ran the following python script in python from anaconda/sanchezlab environment
# import os
# 
# # Change working directory
# os.chdir('/Users/xiujia/Library/CloudStorage/OneDrive-TechnischeUniversitätIlmenau/Data_analysis/Mixing_exp._04-2023/01_16S_amplicon/kraken2_barbell/div_analysis_family_level_kraken2_silva_16S_output_only_bacteria_filter_2_reads/network_Spiec_Easi_rawreads_full')
# 
# # Confirm the change
# print(f"New Directory: {os.getcwd()}")
# # In python, use the following code to make 999 random networks based on the edge-list of your observed network. Xiu do you generate the null model by "Random rewiring: Shuffle edges randomly while preserving the degree distribution."
# import numpy as np
# import networkx as nx
# import pandas as pd
# from NEMtropy import UndirectedGraph, matrix_generator
# from NEMtropy.network_functions import build_adjacency_from_edgelist
# 
# df = pd.read_csv('network_all_microcosm_filterededgelist.csv') # Change as necessary
# 
# G = nx.from_pandas_edgelist(df,source='V1',target='V2')
# G = G.to_undirected()
# 
# # # Transform into adjacency matrix
# adj_bin = nx.adjacency_matrix(G).toarray()
# 
# dseq= np.sum(adj_bin, axis=1)
# 
# graph = UndirectedGraph(adj_bin)
# 
# graph.solve_tool(model="cm_exp", method="newton", initial_guess="random")
# 
# graph.ensemble_sampler(999, cpu_n=1, output_dir="full_null_ensemble/") # Create a new folder for each observed network (e.g. 1 for full_dataset, 1 for Seawater)
```


### Open the ensemble in R 

#### full_dataset
```{r}

#### import edge list files
temp = list.files(path = paste0(base_path, "full_null_ensemble"), pattern = "*.txt", full.names = TRUE)
read.delim_mod <- function(file_path) {
  read.delim(file_path, header = FALSE)
}

ensemble = lapply(temp, read.delim_mod)

#### read in observed edgelist and adjacency matrix
edgelist_obs <- read.csv(file = paste0(base_path, "full_network_edgelist.csv"))[,-1]
adj_obs <- read.csv(file = paste0(base_path, "full_network_adj_matrix.csv")) %>%
  column_to_rownames(var="X")
colnames(adj_obs) <- seq(1:dim(adj_obs)[1])
adj_obs[1:3, 1:3]


#### functions
ga.func <- function(mat){
  mat <- graph_from_adjacency_matrix(mat,mode=c("undirected"))
  mat
}

ge.func <- function(mat){
  mat <- graph_from_edgelist(mat,directed=FALSE)
  mat
}

## Checks - do the edgelist and adjacency matrix give the same pairs?
graph.obs <- ga.func(as.matrix(adj_obs))
graph.obs
graph.obs <- ge.func(as.matrix(edgelist_obs))
graph.obs
# Xiu: yes, they are same

#### Make ensemble matrices edge list, graphs, and adjacency matrix
edge.f <- function(edgelist){
  newlist <- strsplit(edgelist$V1," ")
  newlist <- do.call(rbind, newlist)
  newlist
}

ens.ed.ls <- lapply(ensemble,edge.f)
graph.ens <- lapply(ens.ed.ls,ge.func)

graph.ens[1]
graph.obs <- ge.func(as.matrix(edgelist_obs))


#### Rebuild disconnected nodes into the ensemble adj
#### ensemble adj
get_asj <- function(graph){
  mat <- as.matrix(as_adjacency_matrix(graph))
  mat
}
ens_adj <- lapply(graph.ens,get_asj)
ens_adj[[1]][1:5, 1:5]


#### rebuild
rebuild_f <- function(obs.m,ens.m){
  # obs.m <- get_asj(graph.obs)
  # ens.m <- ens_adj[[2]]
  
  colnames(obs.m) <- seq(1:dim(obs.m)[1])
  
  rm <- matrix(0,dim(obs.m)[1]-dim(ens.m)[1],dim(ens.m)[1])
  ens.m1 <- rbind(ens.m,rm)
  # dim(ens.m1)
  cm <- matrix(0,dim(obs.m)[1],dim(obs.m)[1]-dim(ens.m)[1])
  ens.m2 <- cbind(ens.m1,cm)
  dim(ens.m2)
  
  
  colvec <- 1 +as.numeric(colnames(ens.m))
  disc <- setdiff(seq(1:dim(obs.m)[1]),colvec)
  colnames(ens.m2) <- c(colvec,disc)
  
  row.names(ens.m2) <- colnames(ens.m2)
  order <- as.character(sort(as.numeric(colnames(ens.m2))))
  ens.m2 <- reorder_mat(mat = ens.m2, order = order)
  
  ens.m2
  
}

rebuild_f(get_asj(graph.obs),ens_adj[[2]])[1:5, 1:5]
ens.list.adj <- lapply(ens_adj,rebuild_f,obs.m=get_asj(graph.obs))

##### Reconvert full ens.adj into igraph object, re-name for quicker loading
ens.list.graph <- lapply(ens.list.adj,ga.func)
ens.list.graph[[1]]
ens.list.graph[[2]]
full_graph <- ens.list.graph # this is now your ensemble of null models for the full_dataset network

```

# Step 5: Calculate network topology 
Calculate the measures of topology that are of interest and bind them into a dataframe
There are many, many different measures of topology to choose from. Generally, we are interested in network stability and complexity.
Check out igraph for many options. Measures used for neural or social networks may also be interesting (e.g. the robustness function we use here was made to analyze MRI data)

## First - Observed network -

### Measures related to STABILITY -----------------------

#### Robustness 
Run robustness analysis by removing vertices (nodes) based on degree connectivity.\n
This `robust` function performs a “targeted attack” of a graph or a “random failure” analysis, calculating the size of the largest component after edge or vertex removal.
```{r}

#  find the largest component. this is not relevant to the final plot
g <- graph_from_adjacency_matrix(adj_network_full_filtered)
components <- clusters(g)
largest_component <- induced_subgraph(g, which(components$membership == which.max(components$csize)))
largest_component

# run robust
robust <- robustness(ig_network_full_filtered, type = c("vertex"), measure = c("degree"))

# check
ggplot(data=robust, aes(x=removed.pct, y=comp.pct)) +
  geom_line(linewidth = 1.5)

# robust_obs
robust_full_filtered <- robust %>%
  mutate(datasetname = "full")
head(robust_full_filtered)

write.csv(robust_full_filtered, paste0(base_path, "robust_obs.csv"))

```


#### AUC
```{r}

#Lmax = maximum number of possible links in network = N(N-1)/2 (definition from network science book)
## N = total number of nodes in the network
network <- ig_network_full_filtered
vcount(network) 
(Lmax <- (vcount(network) * (vcount(network) - 1))/2)

auc <- robust %>%
  summarise(AUC = AUC(removed.pct,comp.pct)) %>%
  mutate(Lmax = Lmax, 
         AUC_norm = AUC/Lmax)
auc

```


#### Measures related to COMPLEXITY -----------------------
```{r}

#### Transitivity ------------------------
trans <- transitivity(ig_network_full_filtered, type = "average") 
trans <- trans %>%
  as.data.frame() %>%
  dplyr::rename("transitivity" = ".")
print(trans)


#### Betweenness centrality --------------------
between <- mean(igraph::betweenness(ig_network_full_filtered))
between <- between %>%
  as.data.frame() %>%
  dplyr::rename("betweenness_centrality" = ".")
print(between)


#### Modularity ----------------------
mod = cluster_fast_greedy(ig_network_full_filtered) # use the igraph object where all weights are +
print(mod)
mean_mod <- modularity(mod)
mean_mod <- as.data.frame(mean_mod)
print(mean_mod)


### Module membership ------------------
mod_member <- membership(mod)
mod_member_full_filtered <- as.data.frame(mod_member) %>%
  rename("module" = "x") %>%
  rownames_to_column(var = "ASV") %>%
  mutate(datasetname="full")
head(mod_member_full_filtered)


# Combine network properties 
list_data = list(trans,mean_mod, between, auc)
netprop_full_filtered <- list_data %>% 
  purrr::reduce(cbind) %>%
  pivot_longer(cols = c(1:6), names_to = "network_property", values_to = "value") %>%
  mutate(datasetname="full")
print(netprop_full_filtered)
write.csv(netprop_full_filtered, paste0(base_path, "net_prop_obs.csv"))

# mod_mem_obs
mod_member_full_filtered <- mod_member
df_full <- data.frame(Family = names(mod_member_full_filtered),
                      Count = as.numeric(mod_member_full_filtered)) %>% 
  column_to_rownames(var = "Family")
mod_mem_all <- as.data.frame(t(df_full))
mod_mem_all[, 1:5]
write.csv(mod_mem_all, paste0(base_path, "mod_mem_obs.csv"))

```


#### Network properties  
Number of positive and negative edges.  
```{r}

betaMat=as.matrix(symBeta(getOptBeta(network_full_filtered)))

# We divide by two since an edge is represented by two entries in the matrix.
positive=length(betaMat[betaMat>0])/2 
negative=length(betaMat[betaMat<0])/2 
total=length(betaMat[betaMat!=0])/2 

cat("number of total edges is", total,
    "\nnumber of positive", positive,
    "\nnumber of negative", negative)

```


## Second - Null model ensemble

```{r}

# 'full_graph' is the list of 999 null models

#### Robustness ----------
robust.func <- function(graph){
  graph.r <- robustness(graph, type = c("vertex"), measure = c("degree"))
  graph.r
}
ens.robust <- lapply(full_graph,robust.func)

#### Save
df <-  as.data.frame(do.call(rbind, ens.robust))
df1 <- df %>%
  group_by(removed.pct) %>%
  summarise(comp.pct = mean(comp.pct))

robust_all_full <- df %>%
  mutate(datasetname="full",
         model_type ="null") 

write.csv(robust_all_full, paste0(base_path, "robust_ensemble.csv"))

robust_mean_full <- df1 %>%
  mutate(datasetname="full",
         model_type ="null") 

write.csv(robust_mean_full, paste0(base_path, "robust_ensemble_mean.csv"))

### Check 
ggplot(data=df, aes(x=removed.pct, y=comp.pct)) +
  geom_line(linewidth = 1.5, alpha = 0.1) +
  geom_line(data=df1, aes(x = removed.pct, y = comp.pct), colour ="lightgray")

#### AUC ----------------------------------
# ens.robust is the list of 999 null models with robustness calculated
df <- tibble(ID = seq_along(ens.robust)) %>%
  mutate(Objects = map(ens.robust, as_tibble)) %>%
  unnest(Objects)
head(df)

auc <- df %>%
  group_by(ID) %>%
  summarise(AUC = AUC(removed.pct,comp.pct)) %>%
  rename("value" = "AUC") %>%
  dplyr::select(-"ID") %>%
  mutate(variable = "AUC")
print(auc)

#### Transivity -----------------------
transt.func <- function(graph){
  graph.tr <- transitivity(graph, type = "average")
  graph.tr
}

ens.trans <- lapply(full_graph,transt.func)

null.d.metric <- unlist(ens.trans)
trans <- as.data.frame(null.d.metric) %>%
  mutate(variable = "transitivity") %>%
  rename("value" = "null.d.metric")

## Check 
ggplot(data = trans, aes(x =null.d.metric )) +
  geom_histogram(color="black", fill="white", bins = 10) +
  theme_bw()

#### Betweenness centrality --------------------
bet.func <- function(graph){
  graph.b <- mean(igraph::betweenness(graph))
  graph.b
}
ens.bet <- lapply(full_graph,bet.func)

#### Save
bet <-  as.data.frame(do.call(rbind, ens.bet)) %>%
  mutate(variable = "betweenness_centrality") %>%
  rename("value" = "V1")


#### Modularity ----------------------
mod.func <- function(graph){
  graph.m <- modularity(cluster_fast_greedy(graph))
  graph.m
}
ens.mod <- lapply(full_graph,mod.func)

#### Save
mod <-  as.data.frame(do.call(rbind, ens.mod)) %>%
  mutate(variable = "modularity") %>%
  rename("value" = "V1")

# Bind null ensemble topology --------------------
net_prop_full_ensemble <- rbind(mod,bet,trans,auc) %>%
  mutate(datasetname = "full")

write.csv(net_prop_full_ensemble, paste0(base_path, "ensemble_topology.csv"))

```

# Step 6: compare network topology of the observed networks and the ensemble 
```{r}

# Network properties related to stability 
robust_obs <- read.csv(paste0(base_path, "robust_obs.csv")) %>%
  mutate(model_type = "observed")

robust_ens_all <- read.csv(paste0(base_path, "robust_ensemble.csv")) %>%
  mutate(model_type = "null") # all of the ensemble models

robust_ens_mean <- read.csv(paste0(base_path, "robust_ensemble_mean.csv")) %>%
  mutate(model_type = "null") # mean of the ensemble models

# Network properties related to complexity 
net_prop_obs <- read.csv(paste0(base_path, "net_prop_obs.csv")) %>%
  mutate(model_type = "observed")

net_prop_ens <- read.csv(paste0(base_path, "ensemble_topology.csv")) %>%
  rename(network_property = variable) %>%
  mutate(model_type = "null")

head(net_prop_obs)
head(net_prop_ens)

net_prop_all <- rbind(net_prop_obs, net_prop_ens)


#### Robustness figure----------
# Observed models
head(robust_obs)
head(robust_ens_mean)

robust_obs1 <- robust_obs %>%
  select(c( "X", "comp.pct","removed.pct","datasetname","model_type"))


robust_all <- rbind(robust_obs1, robust_ens_mean)
head(robust_all)

##### Robustness
plot <- ggplot(data=robust_all, aes(x=removed.pct, y=comp.pct,  linetype = model_type)) +
  geom_line(data=robust_ens_all, aes(x=removed.pct, y=comp.pct, colour = datasetname), color = "lightgray", alpha=0.1, linewidth=1.5) + # this is the mean of the ensemble
  geom_line(linewidth = 1, color = "darkred") +
  scale_linetype_manual(values=c(2,1), name = "Model type") +
  labs(title = "Robustness of the network of full dataset", 
       y = "Size of largest component",
       x = "Percentage of nodes removed", 
       caption = "Solid lines indicate observed network model\nThe shaded area is the 999 null models") +
  theme(axis.title.y=element_text(size=11, colour = "black", margin=(margin(0,10,0,0)))) +
  theme(axis.title.x=element_text(size=11, colour = "black", margin=(margin(0,10,0,0)))) +
  theme(axis.text=element_text(size=10, hjust = 1)) +
  theme(strip.text.x=element_text(size=12)) +
  theme_few() 
plot 

##### Area under the curve 
d <- net_prop_all %>%
  filter(network_property == "AUC" & model_type == "null")
d1 <- net_prop_all %>%
  filter(network_property == "AUC" & model_type == "observed")

plot1 <- ggplot() +
  geom_violin(data = d, aes(x = datasetname, y = value), fill = "steelblue", alpha = 0.3) +
  geom_point(data = d1, aes(x = datasetname, y = value), colour = "steelblue", size = 3) +
  labs(y = "Area",
       title = "Area under the curve") +
  theme_few() +
  theme(strip.text.x=element_text(size=12),
        legend.position = "none")
plot1

fig <- plot_grid(plot, plot1, nrow=1, rel_widths = c(5,3))
fig
# ggsave(paste0(base_path, "Network_robustness.png"), plot = fig, width = 14, height = 7, dpi = 300)

#### Network complexity figure -------------------------
names(net_prop_all)
levels(as.factor(net_prop_all$network_property))

##### Betweenness centrality
d <- net_prop_all %>%
  filter(network_property == "betweenness_centrality" & model_type == "null")
d1 <- net_prop_all %>%
  filter(network_property == "betweenness_centrality" & model_type == "observed")

plot2 <- ggplot() +
  geom_violin(data = d, aes(x = datasetname, y = value), fill = "steelblue", alpha = 0.3) +
  geom_point(data = d1, aes(x = datasetname, y = value), color = "steelblue", size = 3, alpha = 0.3) +
  labs(y = "Number of shortest paths",
       title = "Betweenness centrality") +
  theme_few() +
  theme(strip.text.x=element_text(size=12))


##### Modularity
d <- net_prop_all %>%
  filter(network_property == "modularity" & model_type == "null")
d1 <- net_prop_all %>%
  filter(network_property == "mean_mod" & model_type == "observed")

plot3 <- ggplot() +
  geom_violin(data = d, aes(x = datasetname, y = value), fill = "steelblue", alpha = 0.3) +
  geom_point(data = d1, aes(x = datasetname, y = value), colour = "steelblue", size = 3, alpha = 0.3) +
  labs(y = "Modularity (Q)",
       title = "Modularity") +
  theme_few() +
  theme(strip.text.x=element_text(size=12))


##### Transitivity
d <- net_prop_all %>%
  filter(network_property == "transitivity" & model_type == "null")
d1 <- net_prop_all %>%
  filter(network_property == "transitivity" & model_type == "observed")

plot4 <- ggplot() +
  geom_violin(data = d, aes(x = datasetname, y = value), fill = "steelblue", alpha = 0.3) +
  geom_point(data = d1, aes(x = datasetname, y = value), colour = "steelblue", size = 3, alpha = 0.3) +
  labs(y = "Clustering coefficient",
       title = "Transitivity") +
  theme_few() +
  theme(strip.text.x=element_text(size=12))


### Combine -----------
legend <- get_legend(plot2)
fig <- plot_grid(plot1 +theme(legend.position = "none"),
                 plot2 +theme(legend.position = "none"),
                 plot3 +theme(legend.position = "none"),
                 plot4 +theme(legend.position = "none"),
                 nrow = 1)

fig2 <- plot_grid(plot, fig, legend, nrow=1, rel_widths = c(3, 8, 0.5))
fig2

ggsave(paste0(base_path, "Network_properties_robustness_frequency_4.png"), plot = fig2, width = 20, height = 4, dpi = 300, background = "white")

```

# Step 7: Prepare the final network figures 

#### full_dataset networks 
```{r }
# Xiu something wrong here
# Module information
mod_mem <- read.csv(paste0(base_path, "mod_mem_obs.csv")) %>%
  pivot_longer(cols = -X, names_to = "Family",
               values_to = "module")
head(mod_mem)

mod_mem_full <- mod_mem %>%
  # filter(X == "mod_member_full") %>%
  mutate(Family_name = Family) %>%
  column_to_rownames(var = "Family_name")

head(mod_mem_full)

# Re-load the network made in Spiec.Easi/igraph
network_full <- readRDS(paste0(base_path, "network_full_filtered.rds"))
temp <- symBeta(getOptBeta(network_full), mode="maxabs")
weight <- Matrix::summary(t(temp))[,3]

# re-make network in igraph
ig_network_full <- adj2igraph(getRefit(network_full),diag=TRUE,
                              edge.attr=list(weight=weight),
                              vertex.attr=list(name=taxa_names(ps_rawreads_filtered)))


#Increase visualization
full_net <- asNetwork(ig_network_full)
network::set.edge.attribute(full_net, "color", ifelse(full_net %e% "weight" > 0, "steelblue", "orange"))


### Add information to determine the largest clusters
t <- mod_mem_full %>%
  group_by(module) %>%
  count()

mod_mem2 <- mod_mem_full %>%
  inner_join(t, by= "module") %>%
  mutate(module = as.factor(module)) %>%
  arrange(desc(n)) 

head(mod_mem2)

# Define the order of levels in the legend
desired_order <- mod_mem2 %>%
  select(module) %>%
  distinct()
desired_order <- as.character(desired_order$module)

# Define custom labels for the levels 
t <- mod_mem2 %>%
  select(module, n) %>%
  distinct() %>%
  mutate(label = paste0("Module", module, ", n =", n)) %>%
  mutate(alpha = ifelse(n > 25, 0.8, 0.3))

table(t$n)

t1 <- as.numeric(t$alpha)
t1

t2 <- t
head(t2)

# Adjust nodesize
otu_table <- otu_table(ps_rawreads_filtered)
otu_df <- as.data.frame(otu_table) # check that it has 64 columns
nodesize <- rowMeans(clr(otu_table)) +3 

vertex_names <- V(ig_network_full)$name
names(nodesize) <- vertex_names
full_net %v% "nodesize" <- nodesize[vertex_names]
nr_nodes <- length(full_net %v% "nodesize") # check the length
# length(full_net %v% "nodesize") # check the length


#Add module information (which Family is in which module)
mods <- map_levels(rownames(otu_df), from = "Family", to = "module", mod_mem2)
m <- as.data.frame(mods)
full_net %v% "module" <- mods


#Make network plot
mycolors <- scale_color_manual(values = c("#FFFF99", "#8DD3C7", "#FB9A99", "#8DA0CB", "#984EA3", "#DECBE4", "#E41A1C", "#E5D8BD", "#E5C494", "#666666", "#7570B3", "#CCEBC5", "#FFF2AE", "#BEAED4", "#FBB4AE", "#B2DF8A", "#B3B3B3", "#FC8D62", "#FFD92F", "#377EB8", "#FDC086", "#4DAF4A", "#999999", "#7FC97F", "#CCCCCC", "#FF7F00"),  breaks = desired_order, labels = t2$label)


# qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
# set.seed(011235)
# col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
# col <- sample(col_vector, 26)
# col

set.seed(123)
plot_full <- ggnet2(full_net, 
                    node.color = "module", 
                    alpha = "module",
                    edge.alpha = 0.5,
                    label = F, 
                    node.size = "nodesize", 
                    label.size = 2, 
                    edge.color = "color",
                    mode = "fruchtermanreingold") + 
  mycolors +
  guides(color=guide_legend(title="Modules"), size = "none") +
  labs(title = "",
       caption = paste0("total nodes/taxa = ", nr_nodes)) +
  theme(plot.title = element_text(hjust = 0.5)) 

plot_full



ggsave(paste0(base_path, "Network_full_frequency_4_new.png"), plot_full, width = 8, height = 6, dpi = 300)


# full network module membership ---------------
mod_mem_df <- as.data.frame(rowSums(otu_df)) %>%
  rename(reads = `rowSums(otu_df)`) %>%
  rownames_to_column(var = "Family") %>%
  inner_join(mod_mem_full, by = "Family") %>%
  filter(reads>0)
names(mod_mem_df)

# Figure
plot_mod_mem_full <- ggplot(data=mod_mem_df) +
  geom_bar(stat="identity", aes(x = Family,y = reads, fill = Family)) +
  facet_wrap(.~module, scales = "free_y") +
  theme_few() +
  labs(title = "Module membership of full_dataset",
       caption = "Bacterial family with > geometric mean",
       y = "Read number",
       x = "") +
  theme(plot.title = element_text(size = 20),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold", size = 18),
        legend.position = "none") +
  coord_flip()

plot_mod_mem_full

ggsave(paste0(base_path, "Mod_mem_full_frequency_4.png"), plot_mod_mem_full, width = 20, height = 12, dpi = 300)

```


#### make correlations
```{r}

# load the module list
df <- read.csv(paste0(base_path, "module_list.csv"), header = TRUE, row.names = 1)
str(df)

# check how many families in each module
table(df$Group)

# calculate relative abundance 
com_tot_family_rel <- data.frame(otu_table(ps_rawreads)) %>%
  mutate(across(everything(), ~ .x / sum(.x)))

dim(com_tot_family_rel)
com_tot_family_rel[1:3, 1:3]

# for module 1
module_1 <- df %>% 
  filter(Group == 1)

module_1 <- module1$Item

# Filter rows based on row names
df_modue_1 <- com_tot_family_rel[row.names(com_tot_family_rel) %in% module_1, ]

dim(df_modue_1)

```


### Session Info
```{r}
sessionInfo()
```
